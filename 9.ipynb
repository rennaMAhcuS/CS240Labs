{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/labuser/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/labuser/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import corpus\n",
    "import numpy as np\n",
    "\n",
    "# Download the Brown corpus and the universal tagset\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"universal_tagset\")\n",
    "\n",
    "# Get the tagged sentences from the Brown corpus\n",
    "tagged_sentences = list(corpus.brown.tagged_sents(tagset=\"universal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in tagged_sentences[:10]:\n",
    "#     for word_tuple in sentence:\n",
    "#         print(word_tuple[0], end=\" \")\n",
    "#     print()\n",
    "\n",
    "pos = {\n",
    "    \"ADJ\": 1,\n",
    "    \"ADP\": 2,\n",
    "    \"ADV\": 3,\n",
    "    \"CONJ\": 4,\n",
    "    \"DET\": 5,\n",
    "    \"NOUN\": 6,\n",
    "    \"NUM\": 7,\n",
    "    \"PRON\": 8,\n",
    "    \"PRT\": 9,\n",
    "    \"VERB\": 10,\n",
    "    \".\": 11,\n",
    "    \"X\": 12,\n",
    "}\n",
    "# beginning = 0, ending = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkov:\n",
    "    def __init__(self, tagged_sentences, pos):\n",
    "        self.tagged_sentences = tagged_sentences\n",
    "        self.pos = pos\n",
    "        self.word_map = {}\n",
    "\n",
    "        self.train_sets = []\n",
    "        self.test_sets = []\n",
    "        self.transition_matrix = []\n",
    "        self.emission_matrices = []\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_map(self) -> dict:\n",
    "        id = 0\n",
    "        for sentence in tagged_sentences:\n",
    "            for word, _ in sentence:\n",
    "                if word in self.word_map.keys():\n",
    "                    continue\n",
    "                self.word_map[word] = id\n",
    "                id += 1\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_transition_matrix(self, tagged_sentence) -> np.ndarray:\n",
    "        transition_matrix = np.ones((14, 14))\n",
    "        for sentence in tagged_sentence:\n",
    "            n = len(sentence)\n",
    "            for i in range(n):\n",
    "                word, tag = sentence[i]\n",
    "                tag = pos[tag]\n",
    "                if i == 0:\n",
    "                    transition_matrix[0][tag] += 1\n",
    "                elif i < n - 1:\n",
    "                    transition_matrix[tag][pos[sentence[i + 1][1]]] += 1\n",
    "                else:\n",
    "                    transition_matrix[tag][13] += 1\n",
    "\n",
    "        transition_matrix = transition_matrix / np.sum(\n",
    "            transition_matrix, axis=1, keepdims=True\n",
    "        )\n",
    "\n",
    "        return transition_matrix\n",
    "\n",
    "    def get_emission_matrix(self, tagged_sentence) -> np.ndarray:\n",
    "        n = len(self.word_map)\n",
    "        emission_matrix = np.ones((14, n))\n",
    "        for sentence in tagged_sentence:\n",
    "            for word, tag in sentence:\n",
    "                tag = pos[tag]\n",
    "                emission_matrix[tag][self.word_map[word]] += 1\n",
    "\n",
    "        emission_matrix = emission_matrix / np.sum(\n",
    "            emission_matrix, axis=1, keepdims=True\n",
    "        )\n",
    "\n",
    "        return emission_matrix\n",
    "\n",
    "    def five_fold(self):\n",
    "        n = len(self.tagged_sentences)\n",
    "        sz = n // 5\n",
    "        parts = []\n",
    "        for i in range(5):\n",
    "            parts.append(tagged_sentences[i * sz : i * sz + sz])\n",
    "        for i in range(5):\n",
    "            self.test_sets.append(parts[i])\n",
    "            train_set = []\n",
    "            for j in range(5):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                train_set.extend(parts[i])\n",
    "\n",
    "            self.train_sets.append(train_set)\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_five_fold_matrices(self):\n",
    "        self.train_sets = []\n",
    "        self.test_sets = []\n",
    "        self.five_fold()\n",
    "        self.get_map()\n",
    "        for i in range(5):\n",
    "            self.transition_matrix.append(\n",
    "                self.get_transition_matrix(self.train_sets[i])\n",
    "            )\n",
    "            self.emission_matrices.append(self.get_emission_matrix(self.train_sets[i]))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HiddenMarkov(tagged_sentences=tagged_sentences, pos=pos)\n",
    "model.get_five_fold_matrices()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
